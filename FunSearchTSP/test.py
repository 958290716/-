
API_KEY = 'sk-1OSRJL4lx8BB2aB4EHG2GTdM9oPDefzChBrDk8xLoP6zPoha'



def _trim_preface_of_body(sample: str) -> str:
    """Trim the redundant descriptions/symbols/'def' declaration before the function body.
    Please see my comments in sampler.LLM (in sampler.py).
    Since the LLM used in this file is not a pure code completion LLM, this trim function is required.

    -Example sample (function & description generated by LLM):
    -------------------------------------
    This is the optimized function ...
    def priority_v2(...) -> ...:
        return ...
    This function aims to ...
    -------------------------------------
    -This function removes the description above the function's signature, and the function's signature.
    -The indent of the code is preserved.
    -Return of this function:
    -------------------------------------
        return ...
    This function aims to ...
    -------------------------------------
    """
    lines = sample.splitlines()
    func_body_lineno = 0
    find_def_declaration = False
    for lineno, line in enumerate(lines):
        # find the first 'def' statement in the given code
        if line[:3] == 'def':
            func_body_lineno = lineno
            find_def_declaration = True
            break
    if find_def_declaration:
        code = ''
        for line in lines[func_body_lineno + 1:]:
            code += line + '\n'
        return code
    return sample

import json
import multiprocessing
from typing import Collection, Any
import http.client
from implementation import sampler

class LLMAPI(sampler.LLM):
    """Language model that predicts continuation of provided source code.
    """

    def __init__(self, samples_per_prompt: int, trim=True):
        super().__init__(samples_per_prompt)
        additional_prompt = ('Complete a different and more complex Python function. '
                             'Be creative and you can insert multiple if-else and for-loop in the code logic.'
                             'Only output the Python code, no descriptions.'
                             'Please do not modify the data type and quantity of the function return value.'
                             'Please consider the computational efficiency of the algorithm.'
                             'Please do not modify the input object of the function, but create a copy of it if you want to use it.'
                             'This is a function of the TSP problem, used to determine the next city node to visit. The city with the highest score will be the next city.')
        self._additional_prompt = additional_prompt
        self._trim = trim

    def draw_samples(self, prompt: str) -> Collection[str]:
        """Returns multiple predicted continuations of `prompt`."""
        return [self._draw_sample(prompt) for _ in range(self._samples_per_prompt)]

    def _draw_sample(self, content: str) -> str:
        prompt = '\n'.join([content, self._additional_prompt])
        while True:
            try:
                conn = http.client.HTTPSConnection("api.chatanywhere.com.cn")
                payload = json.dumps({
                    "max_tokens": 512,
                    "model": "gpt-3.5-turbo",
                    "messages": [
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ]
                })
                headers = {
                    'Authorization': f'Bearer {API_KEY}',
                    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',
                    'Content-Type': 'application/json'
                }
                conn.request("POST", "/v1/chat/completions", payload, headers)
                res = conn.getresponse()
                data = res.read().decode("utf-8")
                data = json.loads(data)
                response = data['choices'][0]['message']['content']
                # trim function
                if self._trim:
                    response = _trim_preface_of_body(response)
                return response
            except Exception:
                continue


from implementation import evaluator
from implementation import evaluator_accelerate


class Sandbox(evaluator.Sandbox):
    """Sandbox for executing generated code. Implemented by RZ.

    RZ: Sandbox returns the 'score' of the program and:
    1) avoids the generated code to be harmful (accessing the internet, take up too much RAM).
    2) stops the execution of the code in time (avoid endless loop).
    """

    def __init__(self, verbose=False, numba_accelerate=True):
        """
        Args:
            verbose         : Print evaluate information.
            numba_accelerate: Use numba to accelerate the evaluation. It should be noted that not all numpy functions
                              support numba acceleration, such as np.piecewise().
        """
        self._verbose = verbose
        self._numba_accelerate = numba_accelerate

    def run(
            self,
            program: str,
            function_to_run: str,  # RZ: refers to the name of the function to run (e.g., 'evaluate')
            function_to_evolve: str,  # RZ: accelerate the code by decorating @numba.jit() on function_to_evolve.
            inputs: Any,  # refers to the dataset
            test_input: str,  # refers to the current instance
            timeout_seconds: int,
            **kwargs  # RZ: add this
    ) -> tuple[Any, bool]:
        """Returns `function_to_run(test_input)` and whether execution succeeded.

        RZ: If the generated code (generated by LLM) is executed successfully,
        the output of this function is the score of a given program.
        RZ: PLEASE NOTE THAT this SandBox is only designed for bin-packing problem.
        """
        dataset = inputs[test_input]
        try:
            result_queue = multiprocessing.Queue()

            process = multiprocessing.Process(
                target=self._compile_and_run_function,
                args=(program, function_to_run, function_to_evolve, dataset, self._numba_accelerate, result_queue)
            )
            process.start()
            process.join(timeout=timeout_seconds)
            if process.is_alive():
                # if the process is not finished in time, we consider the program illegal
                process.terminate()
                process.join()
                results = None, False
            else:
                if not result_queue.empty():
                    results = result_queue.get_nowait()
                else:
                    results = None, False
            return results
        except:
            return None, False

    def _compile_and_run_function(self, program, function_to_run, function_to_evolve, dataset, numba_accelerate,
                                  result_queue):
        try:
            # optimize the code (decorate function_to_run with @numba.jit())
            
            # compile the program, and maps the global func/var/class name to its address
            all_globals_namespace = {}
            # execute the program, map func/var/class to global namespace
            exec(program, all_globals_namespace)
            # get the pointer of 'function_to_run'
            function_to_run = all_globals_namespace[function_to_run]
            # return the execution results
            results = function_to_run(dataset)
            # the results must be int or float
            if not isinstance(results, (int, float)):
                result_queue.put((None, False))
                return
            result_queue.put((results, True))
            
        except Exception:
            # if raise any exception, we assume the execution failed
            
            result_queue.put((None, False))


specification = r'''
import numpy as np
def calculate_distance(city1, city2) -> float:  
    """Calculates the Euclidean distance between two cities."""  
    x1 = city1[0]  
    y1 = city1[1]
    x2 = city2[0]
    y2 = city2[1]
    return np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)  

def drop_current_city(coordinate, cities):
    index = np.where(np.all(cities == coordinate, axis=1))[0]
    
    if len(index) > 0:
        new_cities = np.delete(cities, index[0], axis=0)
    else:
        new_cities = cities.copy()
    
    return new_cities
    
def generate_tour(city_coords: np.ndarray[np.ndarray]) -> tuple[np.ndarray,float]: 
    """Generates an initial TSP tour and its total distance.
    Args:
        city_coords: List of tuples representing the (x, y) coordinates of each city.
    Returns:
        A tuple containing:
        - Array of city indices representing the initial tour.
        - Total distance of the initial tour.
    """

                 
    current_city = 0
    unvisited_cities = city_coords.copy()

    current_city_coordinate = np.array(unvisited_cities[current_city])

    
    unvisited_cities = drop_current_city(current_city_coordinate,unvisited_cities)
    tour = [current_city_coordinate]
    total_distance = 0

    for i in range(len(city_coords)-1):

        prioritys = priority(current_city_coordinate,unvisited_cities)

        current_city = np.argmax(prioritys)  

        total_distance += calculate_distance(current_city_coordinate, unvisited_cities[current_city])

        current_city_coordinate = unvisited_cities[current_city]

        tour.append(current_city_coordinate)

        unvisited_cities = drop_current_city(current_city_coordinate,unvisited_cities)
  
    return tour, total_distance
    
@funsearch.run
def evaluate(instances: dict) -> float:  
    distances = []  

    
    for name in instances:  

        instance = instances[name]

        city_coords = np.array(instance['city_coords'])

        tour, distance  = generate_tour(city_coords)

        distances.append(distance)

    return -np.mean(distances)
    
@funsearch.evolve
def priority(current_city: np.ndarray, unvisited_cities: np.ndarray[np.ndarray]) -> np.ndarray: 
    
    x0 = current_city[0]  
    y0 = current_city[1] 
    
    distances = np.ndarray([0])
    for city in unvisited_cities:  
        x = city[0]
        y = city[1]
        dis = np.sqrt((x0 - x) ** 2 + (y0 - y) ** 2)  
        distances = np.append(distances,-dis)
        
    return distances
'''

import  TSPdataset_small

TSPdatasets_01 = {'TSPdatasets_01': TSPdataset_small.datasets['TSPdatasets_01']} 

from implementation import funsearch
from implementation import config

# It should be noted that the if __name__ == '__main__' is required.
# Because the inner code uses multiprocess evaluation.
if __name__ == '__main__':
    class_config = config.ClassConfig(llm_class=LLMAPI, sandbox_class=Sandbox)
    config = config.Config(samples_per_prompt=10, evaluate_timeout_seconds=120)
    global_max_sample_num = 1000   # if it is set to None, funsearch will execute an endless loop
    funsearch.main(
        specification=specification, 
        inputs=TSPdatasets_01, 
        config=config,
        max_sample_nums=global_max_sample_num,
        class_config=class_config,
        log_dir='../logs/funsearch_llm_api'
    )

